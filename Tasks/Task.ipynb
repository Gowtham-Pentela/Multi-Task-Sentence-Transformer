{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries and Pretrained Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.decomposition import PCA\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'usually , he would be tearing around the living room , playing with his toys .'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "dataset = load_dataset(\"bookcorpus\", split=\"train[:1%]\")  \n",
    "\n",
    "print(dataset[0])  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for sentence: usually , he would be tearing around the living room , playing with his toys .\n",
      "[ 2.30240554e-01  2.17634931e-01 -2.30480507e-02  3.15085292e-01\n",
      "  2.91219145e-01 -3.75583172e-01 -1.76689520e-01  3.25360209e-01\n",
      " -2.34617725e-01 -3.77027169e-02 -1.33780628e-01 -1.96146011e-01\n",
      " -1.82651266e-01  2.03661680e-01 -1.52843311e-01  1.86633348e-01\n",
      "  3.19304615e-01  1.92644313e-01 -1.05207711e-01  2.99984425e-01\n",
      "  1.69351678e-02 -1.06273144e-01 -2.86487937e-01  1.42757997e-01\n",
      "  2.25143611e-01 -1.27832353e-01 -1.50291428e-01 -9.98070315e-02\n",
      " -5.64656481e-02 -2.04160735e-01  7.02160671e-02  1.08491760e-02\n",
      "  2.62546688e-01 -1.45309508e-01 -4.52080965e-02 -1.71361640e-01\n",
      " -5.42785525e-02 -1.01067863e-01 -3.12309414e-01  3.60523053e-02\n",
      " -2.09291637e-01 -1.54354811e-01 -1.27532691e-01  8.93664062e-02\n",
      "  4.62390408e-02 -1.75261810e-01  3.67236674e-01 -1.76905230e-01\n",
      " -2.52659922e-03 -2.78656870e-01  3.67837995e-02  3.37552100e-01\n",
      "  5.42776436e-02  1.19919397e-01 -2.39945296e-02  2.71340758e-01\n",
      "  1.94669187e-01 -3.94767851e-01 -1.04157627e-01  1.11291952e-01\n",
      "  2.05641329e-01  9.05632973e-02 -2.11682953e-02 -5.00226468e-02\n",
      "  4.84044403e-02  3.80517662e-01  5.25567755e-02  3.08185101e-01\n",
      " -3.01551610e-01  5.18765021e-03 -2.03993648e-01 -2.26065759e-02\n",
      " -9.57796201e-02 -2.31445536e-01  2.45575637e-01  4.00924474e-01\n",
      "  5.47948256e-02  7.65516162e-02  1.21907659e-01  1.31160110e-01\n",
      " -1.22138336e-01  4.81496990e-01 -1.01515815e-01  3.88338357e-01\n",
      "  1.94132343e-01  1.20429128e-01 -2.53859013e-01  7.27452338e-02\n",
      "  9.73498896e-02  6.03653044e-02 -1.66884020e-01 -1.79191768e-01\n",
      "  1.12298191e-01  3.26944925e-02  5.10369707e-03  3.34675919e-04\n",
      " -1.11939721e-01  7.76968524e-02 -1.49454251e-01  3.76599520e-01\n",
      " -4.45731692e-02 -2.24231988e-01  1.95060670e-02  2.31747434e-01\n",
      " -4.31772843e-02 -8.49460438e-02  3.32584769e-01 -2.20555991e-01\n",
      " -1.58835471e-01  1.62827983e-01 -1.42793149e-01 -4.36728418e-01\n",
      "  1.63671866e-01 -1.18729122e-01 -7.47481883e-02  2.02011913e-01\n",
      "  1.65250480e-01 -4.21046801e-02 -3.16301852e-01  7.56801516e-02\n",
      "  1.04749881e-01 -2.31168926e-01 -1.01873852e-01  5.03999114e-01\n",
      " -1.13901086e-01 -1.50923491e-01 -1.42894080e-02 -9.11117718e-02\n",
      " -1.15927197e-01 -5.33112407e-01  5.30653775e-01  2.86146730e-01\n",
      "  3.12240750e-01 -2.57038921e-01 -1.86686799e-01  2.64949471e-01\n",
      "  2.77245641e-01 -9.08676535e-02 -1.15204990e-01 -6.99679600e-03\n",
      "  1.72502190e-01  1.24335429e-03  1.92283392e-01  4.33906280e-02\n",
      "  7.58385137e-02 -1.61193609e-01 -3.84962298e-02 -2.09786594e-01\n",
      "  2.45364290e-02  1.96024314e-01  1.48345664e-01  3.36891785e-02\n",
      " -1.54179245e-01 -4.66660827e-01  2.75316481e-02 -7.78761879e-02\n",
      " -3.84472519e-01  2.97029521e-02 -9.52854827e-02  6.64361939e-02\n",
      "  5.18839955e-02 -1.07248649e-01 -3.24467361e-01  6.20204732e-02\n",
      "  7.60601610e-02  1.45451650e-01  1.71085820e-01  3.30397487e-01\n",
      " -1.34935290e-01  3.53628129e-01 -8.39378871e-03  3.58774185e-01\n",
      "  4.16932851e-01 -2.37408012e-01 -4.46085781e-01  1.63251936e-01\n",
      "  2.99456447e-01 -1.23043008e-01  1.94323868e-01  5.86951673e-02\n",
      " -6.52636468e-01  4.84570861e-02  2.26911485e-01 -6.57704026e-02\n",
      " -1.31062001e-01 -1.26297534e-01  1.12407029e-01 -3.84484321e-01\n",
      " -3.02609473e-01 -1.24790028e-01 -1.48013651e-01 -1.27660066e-01\n",
      "  1.78659987e-02  2.13828623e-01 -6.08775355e-02 -2.61861622e-01\n",
      "  4.35960330e-02 -2.53460944e-01  1.26651317e-01 -7.41819218e-02\n",
      " -8.00318643e-02 -5.65914437e-02  3.84764224e-02  2.33845249e-01\n",
      " -2.36684844e-01 -2.07090691e-01 -2.17650309e-01 -2.01458201e-01\n",
      "  9.23363045e-02  1.31388813e-01 -2.38075569e-01  1.89669371e-01\n",
      "  2.43481353e-01  1.33524403e-01 -2.04410970e-01 -3.34127098e-02\n",
      "  1.06079467e-01  1.09985858e-01 -3.35709870e-01 -4.90940101e-02\n",
      " -2.40930200e-01 -3.58907953e-02 -5.38936794e-01  2.70000994e-01\n",
      "  7.73817077e-02  5.41677892e-01  1.42591074e-01 -1.36682302e-01\n",
      " -7.96670392e-02  9.73046422e-02 -3.21988672e-01 -1.46683648e-01\n",
      " -6.95769265e-02 -1.42594025e-01 -3.17292452e-01  5.54639287e-02\n",
      " -1.50378436e-01 -1.36242107e-01 -1.26469657e-01 -3.25680584e-01\n",
      " -2.66469628e-01 -1.07697584e-01  4.91678506e-01 -1.33414017e-02\n",
      "  2.51853913e-01  1.90468505e-01  3.18717211e-02  2.67612219e-01\n",
      " -1.32379115e-01 -8.33112001e-02 -1.96381569e-01 -1.83498681e-01\n",
      "  1.89207479e-01 -4.02316600e-01  6.80775419e-02 -1.46786511e-01\n",
      " -2.70742364e-02  6.69950992e-02  3.38292390e-04  2.66920894e-01\n",
      "  2.62980342e-01  1.06918931e-01  6.12601675e-02 -7.90971592e-02\n",
      " -4.23165113e-01 -4.89145100e-01  2.04068854e-01 -1.86427891e-01\n",
      "  1.63584918e-01  1.40709812e-02  5.01553565e-02 -1.62741635e-02\n",
      "  7.28335679e-02  1.99791178e-01 -3.03317010e-01 -4.10072684e-01\n",
      "  2.75492013e-01 -3.63041088e-03  1.42911956e-01 -3.26308370e-01\n",
      "  2.76436806e-01  1.51222855e-01 -4.00370568e-01  1.98005661e-02\n",
      " -2.14827526e-02 -1.41351279e-02 -1.05491862e-01 -4.04047184e-02\n",
      "  6.47849515e-02  1.95488315e-02  2.62241978e-02  2.50685900e-01\n",
      " -7.29104951e-02  6.92737177e-02 -7.32470676e-02  8.92649889e-02\n",
      "  2.27142219e-02 -3.90028581e-02  1.61247537e-01 -1.86088145e-01\n",
      " -6.44239187e-02  1.77143052e-01  1.32938549e-01  2.22412303e-01\n",
      " -1.39575452e-01  8.46224353e-02 -2.19081238e-01 -3.80076617e-01\n",
      " -4.37652540e+00  7.62720332e-02 -2.71075904e-01 -5.14169410e-02\n",
      "  2.67381400e-01  3.95173430e-02 -1.06714800e-01 -1.60750672e-01\n",
      " -3.39994639e-01  8.99919048e-02 -2.50169963e-01 -1.48876145e-01\n",
      "  3.80562723e-01  1.71467975e-01  1.90738574e-01 -1.16588183e-01\n",
      "  3.47388536e-01 -9.18750912e-02  1.28272800e-02  1.99524127e-02\n",
      " -2.89398849e-01 -1.76197246e-01 -1.45913139e-02 -1.50673896e-01\n",
      "  2.75155038e-01  3.09802026e-01  4.83664349e-02 -5.99411083e-03\n",
      " -1.93967506e-01 -2.19763406e-02 -3.60119224e-01 -3.03981483e-01\n",
      " -1.98789239e-01  2.93266714e-01 -2.55040005e-02 -3.26081216e-02\n",
      " -1.00764455e-02 -9.69306827e-02 -1.73562691e-01  2.18317255e-01\n",
      "  2.20248044e-01 -1.75875977e-01 -1.28288671e-01 -2.53654309e-02\n",
      "  3.39715719e-01  4.32864428e-02  5.04454859e-02 -3.30750227e-01\n",
      " -3.92766930e-02  8.26008916e-02  4.92015660e-01  8.63387063e-02\n",
      " -3.90970632e-02 -1.64576098e-01  7.52551258e-02 -1.85927212e-01\n",
      "  3.83046269e-01  1.41313687e-01 -4.17662770e-01 -4.69279796e-01\n",
      "  1.21706255e-01 -2.38932386e-01 -5.33038199e-01  1.72681302e-01\n",
      "  1.46894855e-02  2.88918298e-02 -1.94226325e-01 -1.58463746e-01\n",
      "  3.52401793e-01  3.23578000e-01 -4.72864211e-02 -5.23528047e-02\n",
      "  4.90281135e-02 -7.05680966e-01  7.89956599e-02  4.28114146e-01\n",
      "  2.40882427e-01 -3.33443061e-02  2.20062494e-01  2.62819882e-02\n",
      " -1.30204320e-01 -2.19494134e-01 -1.67490631e-01 -2.34895386e-02\n",
      " -1.43587679e-01 -5.67300141e-01 -3.02661449e-01  1.86390027e-01\n",
      " -2.09838957e-01 -2.34614357e-01  1.42438754e-01  1.82064846e-01\n",
      "  1.98166430e-01  5.59582282e-03  2.97477186e-01  5.99329919e-02\n",
      "  3.62391807e-02 -1.15991212e-01  9.18393210e-02 -5.14656678e-02\n",
      " -2.31619179e-02 -2.23981753e-01  3.02791953e-01  2.19804123e-01\n",
      " -7.00541064e-02  3.59615684e-02 -4.59776849e-01  1.36271164e-01\n",
      " -6.58130720e-02  2.20390320e-01 -1.27564762e-02 -1.93971410e-01\n",
      "  3.13559324e-01 -3.29864442e-01  7.85753597e-03  1.15852403e-02\n",
      "  4.99379188e-01  6.32580042e-01 -7.35740140e-02 -6.65990338e-02\n",
      " -2.54812151e-01  1.11046359e-01 -4.35119510e-01 -1.23708248e-01\n",
      " -4.70510451e-03  1.21378325e-01  2.61783209e-02 -3.88311774e-01\n",
      "  3.38654548e-01 -8.22503865e-02  1.02750165e-03 -1.19529925e-01\n",
      " -9.23628584e-02  8.33216608e-02  2.47402012e-01  1.30245447e-01\n",
      " -1.14982426e-01 -6.96799815e-01 -1.44391820e-01  3.87181751e-02\n",
      " -1.97314754e-01  1.05733007e-01 -2.88103595e-02 -2.17241749e-01\n",
      " -1.64669514e-01  2.69146472e-01 -1.17627628e-01 -1.58535734e-01\n",
      "  1.84560269e-01  1.51375219e-01 -2.31273159e-01  5.71532100e-02\n",
      "  1.81691498e-01  1.04911692e-01  1.98745262e-02  3.00057940e-02\n",
      " -1.78291172e-01 -1.07979938e-01  6.67978302e-02 -1.97618857e-01\n",
      " -8.42620153e-03  2.49783829e-01  2.39517748e-01  1.53609216e-01\n",
      " -1.38155311e-01  3.26872408e-01  6.23014122e-02  7.53904344e-04\n",
      "  2.37484090e-02  3.41164589e-01  6.64396212e-02 -1.77308410e-01\n",
      "  1.49574354e-01  3.88855785e-02 -4.46416251e-03  2.31209934e-01\n",
      " -1.42895848e-01 -2.73786068e-01 -1.67613611e-01  1.10970266e-01\n",
      " -1.37255237e-01  2.94445967e-03 -2.53370926e-02 -2.32391000e-01\n",
      "  1.79129586e-01 -1.60680059e-02  1.48515612e-01  1.56171471e-01\n",
      "  2.79573929e-02  4.93359789e-02 -2.45703056e-01  2.58447498e-01\n",
      " -2.23481908e-01  7.63985980e-03 -2.73766667e-01 -1.66532397e-01\n",
      "  2.15181485e-01  1.01530530e-01  6.84678704e-02  6.19431436e-02\n",
      "  2.60759071e-02 -1.88517585e-01 -1.72823131e-01 -1.03241168e-01\n",
      " -5.81604652e-02 -1.61523849e-01  2.86606729e-01 -2.39595701e-03\n",
      " -1.36435091e-01  1.75101772e-01 -2.54115403e-01 -4.28156592e-02\n",
      " -2.99097031e-01 -1.35873601e-01  1.40814796e-01  2.59694129e-01\n",
      "  1.70436770e-01  2.69516427e-02  2.29331613e-01 -4.42932658e-02\n",
      " -3.04650962e-01 -5.65572903e-02 -8.41311887e-02  3.42247821e-03\n",
      " -3.53866637e-01 -2.83062935e-01 -1.22131236e-01 -2.37558365e-01\n",
      "  2.40869597e-02 -3.37834060e-01  1.81155667e-01 -2.17858598e-01\n",
      "  8.85771215e-02  1.88395858e-01 -2.06460729e-02  1.14586838e-01\n",
      "  1.54663131e-01 -3.50970514e-02  1.75163209e-01  2.68476486e-01\n",
      "  2.38472074e-01 -1.85494751e-01 -2.79437631e-01 -2.47958824e-01\n",
      "  5.69849685e-02 -5.45760207e-02  5.33648767e-02  2.98802227e-01\n",
      "  1.48295745e-01 -9.88711193e-02  3.40931676e-02 -8.55911300e-02\n",
      " -2.90991529e-03  2.37042792e-02 -1.36692479e-01 -4.45288807e-01\n",
      " -4.51513290e-01 -1.34002730e-01  1.88345805e-01 -7.36733079e-02\n",
      " -2.02355713e-01 -4.52721007e-02  3.04135326e-02  2.16101006e-01\n",
      "  2.80132234e-01  1.66159257e-01  9.17580426e-02  1.87484980e-01\n",
      "  1.14724085e-01 -1.69893610e-03 -1.00000180e-01 -3.62459831e-02\n",
      "  1.03976749e-01 -3.06380913e-02  2.81749554e-02  1.09905317e-01\n",
      "  1.24152161e-01 -3.04177850e-01  5.03531992e-02 -2.49135688e-01\n",
      " -2.06313774e-01  2.09760159e-01  9.23260748e-02 -2.50736196e-02\n",
      " -1.70925856e-01 -9.52483118e-02 -1.76035210e-01  1.80811703e-01\n",
      " -1.04643434e-01  1.27664274e-02  1.65337369e-01  1.92189321e-01\n",
      "  2.41554454e-01  3.03122103e-01  2.81495035e-01  1.66356176e-01\n",
      "  6.53794289e-01  2.66179949e-01 -1.09043673e-01 -5.98504171e-02\n",
      " -2.28906691e-01  1.03633061e-01 -1.48755675e-02 -9.48945880e-02\n",
      " -4.67501916e-02 -4.99485582e-02  2.11318702e-01  1.87812913e-02\n",
      " -8.21983889e-02  3.18881929e-01  1.70890763e-02 -2.56178528e-01\n",
      "  1.68067425e-01  2.23734990e-01 -5.44595242e-01 -1.38958469e-01\n",
      "  1.14083700e-01 -1.74333826e-01 -1.65137187e-01 -4.86833556e-03\n",
      "  7.28371413e-03 -1.08265676e-01  8.87989923e-02  5.96905574e-02\n",
      "  2.11366236e-01  1.92544296e-01 -1.26385629e-01  5.36154024e-02\n",
      "  1.20695636e-01  3.05843297e-02 -1.46364942e-01  1.88835055e-01\n",
      " -7.42255747e-02  3.62020046e-01  1.13482982e-01 -1.81222260e-01\n",
      "  1.09385625e-01  1.19747259e-01  2.05438346e-01 -3.19659293e-01\n",
      " -1.05594046e-01  1.23051992e-02 -1.23372488e-01  3.78121406e-01\n",
      "  2.29209676e-01  3.78841930e-03  3.01276118e-01 -4.29294109e-01\n",
      "  1.90458298e-01  1.07850410e-01  1.44697949e-01  2.98598439e-01\n",
      "  9.10888016e-02 -2.12946050e-02  2.19454393e-01 -2.56429285e-01\n",
      "  2.83430427e-01  2.03472730e-02  1.35227054e-01  2.34605029e-01\n",
      "  4.16849792e-01  1.91181853e-01  6.99475855e-02 -2.63675123e-01\n",
      " -1.23729631e-01  3.67799789e-01  1.05011985e-01 -3.85250673e-02\n",
      " -1.44568384e-01  2.96525238e-03  2.51974463e-01 -1.37132823e-01\n",
      "  5.64806424e-02 -5.53334206e-02 -1.39133036e-01  1.30256191e-01\n",
      "  2.50842512e-01  2.83595882e-02 -3.33375037e-01  2.21293211e-01\n",
      "  3.34586740e-01  1.24173522e-01 -4.08835620e-01 -3.12186450e-01\n",
      "  4.15125228e-02 -1.75046101e-01  2.30100676e-01 -1.27142623e-01\n",
      "  6.82124346e-02 -4.94060852e-02  6.41598776e-02 -1.76849827e-01\n",
      " -2.90603917e-02 -1.70001790e-01  2.03072831e-01 -3.57443660e-01\n",
      " -1.59263220e-02  1.13071911e-01  3.69718254e-01 -2.94724166e-01\n",
      "  1.48833647e-01 -1.30092680e-01 -2.58097976e-01  2.42250934e-01\n",
      " -1.34740323e-01  8.04142654e-02  8.78162608e-02 -2.83352643e-01\n",
      " -1.96076810e-01  2.36218601e-01 -6.12859167e-02  2.82264501e-01\n",
      " -2.01008469e-01  7.62652382e-02 -2.33328953e-01 -2.13557288e-01\n",
      "  7.98593611e-02 -4.44831401e-02  7.21958652e-02 -6.55248836e-02\n",
      "  4.44728553e-01 -3.23481932e-02  1.72990739e-01  4.76022549e-02\n",
      " -2.81917483e-01 -2.50021666e-01  2.30266333e-01  5.20448908e-02\n",
      " -1.29776582e-01 -9.31803044e-03 -2.36164361e-01  1.63641915e-01\n",
      " -6.58407584e-02 -1.26935421e-02  5.81647363e-03 -2.94443309e-01\n",
      " -1.72072902e-01 -1.85892686e-01  6.82142973e-02 -3.73416275e-01\n",
      "  2.91014016e-01 -1.60999879e-01 -5.07902429e-02 -3.81985269e-02\n",
      "  1.58833012e-01  9.65953842e-02 -1.36659509e-02  9.97721180e-02\n",
      " -6.88885897e-02 -3.13212156e-01 -1.59771860e-01  1.53911203e-01\n",
      "  5.92351332e-02 -4.73994613e-02  4.02515158e-02 -7.65608773e-02\n",
      "  1.12790637e-01 -2.65520681e-02  1.27695709e-01 -2.31755942e-01]\n"
     ]
    }
   ],
   "source": [
    "def encode_sentences(sentences, tokenizer, model):\n",
    "    \"\"\"\n",
    "    Tokenizes sentences and returns sentence embeddings using a pretrained transformer model.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\", max_length=128)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # Mean pooling over tokens from last hidden layer\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)  \n",
    "\n",
    "    return embeddings\n",
    "sample_sentences = dataset['text'][:20]  \n",
    "embeddings = encode_sentences(sample_sentences, tokenizer, model)\n",
    "embeddings_np = embeddings.numpy()\n",
    "print(f\"Embedding for sentence: {sample_sentences[0]}\")\n",
    "print(embeddings_np[0]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between Sentence 1 and Sentence 2: 0.9201480746269226\n",
      "Cosine similarity between Sentence 1 and Sentence 3: 0.731374204158783\n"
     ]
    }
   ],
   "source": [
    "# Cosine Similarity Calculation\n",
    "sentence1 = \"I love programming.\"\n",
    "sentence2 = \"I enjoy coding.\"\n",
    "sentence3 = \"The weather is nice today.\"\n",
    "embeddings1 = encode_sentences([sentence1], tokenizer, model)\n",
    "embeddings2 = encode_sentences([sentence2], tokenizer, model)\n",
    "embeddings3 = encode_sentences([sentence3], tokenizer, model)\n",
    "similarity_1_2 = cosine_similarity(embeddings1, embeddings2)\n",
    "similarity_1_3 = cosine_similarity(embeddings1, embeddings3)\n",
    "print(f\"Cosine similarity between Sentence 1 and Sentence 2: {similarity_1_2[0][0]}\")\n",
    "print(f\"Cosine similarity between Sentence 1 and Sentence 3: {similarity_1_3[0][0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 'I love programming.'\n",
      "Most similar sentence: 'Coding is my passion.'\n",
      "Similarity: 0.8707\n",
      "\n",
      "Query: 'The weather is great.'\n",
      "Most similar sentence: 'It's sunny outside today.'\n",
      "Similarity: 0.8411\n",
      "\n",
      "Query: 'Who is the author of this book?'\n",
      "Most similar sentence: 'It's sunny outside today.'\n",
      "Similarity: 0.6429\n",
      "\n",
      "Query: 'Why are you here?'\n",
      "Most similar sentence: 'I like solving problems.'\n",
      "Similarity: 0.7068\n",
      "\n",
      "Query: 'Just Kidding'\n",
      "Most similar sentence: 'Coding is my passion.'\n",
      "Similarity: 0.6990\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculation of cosine similarities between query and corpus\n",
    "queries = [\"I love programming.\", \"The weather is great.\",\"Who is the author of this book?\", \"Why are you here?\",\"Just Kidding\"]\n",
    "corpus =  [\"I enjoy outdoor activities.\", \"It's sunny outside today.\", \"I like solving problems.\",\"Coding is my passion.\"]\n",
    "query_embeddings = encode_sentences(queries, tokenizer, model)\n",
    "corpus_embeddings = encode_sentences(corpus, tokenizer, model)\n",
    "similarities = cosine_similarity(query_embeddings, corpus_embeddings)\n",
    "\n",
    "for i, query in enumerate(queries):\n",
    "    most_similar_idx = similarities[i].argmax()\n",
    "    print(f\"Query: '{query}'\\nMost similar sentence: '{corpus[most_similar_idx]}'\\nSimilarity: {similarities[i][most_similar_idx]:.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Infering Model on different DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on STS-B: 3.8571770870588424\n"
     ]
    }
   ],
   "source": [
    "model_name = \"distilbert-base-uncased\"  \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "def encode_sentences(sentences, tokenizer, model):\n",
    "    inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\", max_length=128)\n",
    "    with torch.no_grad():  \n",
    "        outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state.mean(dim=1)  \n",
    "    return embeddings\n",
    "sts_dataset = load_dataset(\"glue\", \"stsb\")\n",
    "\n",
    "sentence_pairs = sts_dataset['test'][:10] \n",
    "\n",
    "embeddings_1 = encode_sentences(sentence_pairs['sentence1'], tokenizer, model)\n",
    "embeddings_2 = encode_sentences(sentence_pairs['sentence2'], tokenizer, model)\n",
    "\n",
    "cos_similarities = cosine_similarity(embeddings_1, embeddings_2)\n",
    "ground_truth = sentence_pairs['label']  \n",
    "cos_similarities_flat = cos_similarities.diagonal()\n",
    "\n",
    "ground_truth_flat = ground_truth[:len(cos_similarities_flat)]\n",
    "mse = mean_squared_error(ground_truth_flat, cos_similarities_flat)\n",
    "print(f\"Mean Squared Error on STS-B: {mse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentence Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape of embeddings: (20, 768)\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "hovertemplate": "PC1=%{x}<br>PC2=%{y}<br>Sentence=%{text}<extra></extra>",
         "legendgroup": "",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers+text",
         "name": "",
         "orientation": "v",
         "showlegend": false,
         "text": [
          "Sentence 1",
          "Sentence 2",
          "Sentence 3",
          "Sentence 4",
          "Sentence 5",
          "Sentence 6",
          "Sentence 7",
          "Sentence 8",
          "Sentence 9",
          "Sentence 10",
          "Sentence 11",
          "Sentence 12",
          "Sentence 13",
          "Sentence 14",
          "Sentence 15",
          "Sentence 16",
          "Sentence 17",
          "Sentence 18",
          "Sentence 19",
          "Sentence 20"
         ],
         "type": "scatter",
         "x": [
          -0.5218220353126526,
          0.5293728113174438,
          0.21040280163288116,
          -2.920665740966797,
          -1.693070650100708,
          2.914417266845703,
          3.941408157348633,
          2.1729609966278076,
          0.5863867998123169,
          -1.4524502754211426,
          -1.0546361207962036,
          0.1919260025024414,
          0.49863579869270325,
          -0.7689555883407593,
          0.004027093295007944,
          -0.5909772515296936,
          0.30407118797302246,
          -1.1417750120162964,
          -1.1041369438171387,
          -0.10511847585439682
         ],
         "xaxis": "x",
         "y": [
          -1.243440866470337,
          -0.8150515556335449,
          -1.3682620525360107,
          0.8844344615936279,
          0.3837442696094513,
          2.1210944652557373,
          -0.6496861577033997,
          -1.0487059354782104,
          0.311850905418396,
          -2.0161244869232178,
          -0.9415509104728699,
          -0.3203176259994507,
          0.3868716359138489,
          2.684589147567749,
          1.6952561140060425,
          0.4039750099182129,
          -0.36285775899887085,
          1.399216890335083,
          -1.5729625225067139,
          0.06792788952589035
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Sentence Embeddings - PCA Projection"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "PC1"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "PC2"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reduce dimensionality to 2D for visualization using PCA\n",
    "print(\"Original shape of embeddings:\", embeddings_np.shape)\n",
    "pca = PCA(n_components=2)\n",
    "reduced_embeddings = pca.fit_transform(embeddings_np)\n",
    "df_embeddings = pd.DataFrame(reduced_embeddings, columns=['PC1', 'PC2'])\n",
    "df_embeddings['Sentence'] = [f\"Sentence {i+1}\" for i in range(len(sample_sentences))]\n",
    "fig = px.scatter(df_embeddings, x='PC1', y='PC2', text='Sentence', title=\"Sentence Embeddings - PCA Projection\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Questions from Requirement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1 embedding shape: (768,)\n",
      "Sentence 2 embedding shape: (768,)\n",
      "Sentence 3 embedding shape: (768,)\n",
      "Sentence 4 embedding shape: (768,)\n",
      "Sentence 5 embedding shape: (768,)\n",
      "Sentence 6 embedding shape: (768,)\n",
      "Sentence 7 embedding shape: (768,)\n",
      "Sentence 8 embedding shape: (768,)\n",
      "Sentence 9 embedding shape: (768,)\n",
      "Sentence 10 embedding shape: (768,)\n",
      "Sentence 11 embedding shape: (768,)\n",
      "Sentence 12 embedding shape: (768,)\n",
      "Sentence 13 embedding shape: (768,)\n",
      "Sentence 14 embedding shape: (768,)\n",
      "Sentence 15 embedding shape: (768,)\n",
      "Sentence 16 embedding shape: (768,)\n",
      "Sentence 17 embedding shape: (768,)\n",
      "Sentence 18 embedding shape: (768,)\n",
      "Sentence 19 embedding shape: (768,)\n",
      "Sentence 20 embedding shape: (768,)\n"
     ]
    }
   ],
   "source": [
    "# Checking if The model is encoding input sentences into fixed-length embeddings\n",
    "for i, embedding in enumerate(embeddings_np):\n",
    "    print(f\"Sentence {i+1} embedding shape: {embedding.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThere are a few choices made regarding the model architecture outside of the transformer backbone. These include:\\na. Pooling Strategy (Mean Pooling):After passing the sentences through the transformer model, the code extracts the embeddings from the last hidden state.\\nThe embeddings are then aggregated using mean pooling over the tokens (i.e., taking the average of all token embeddings for a given sentence).\\nThis is an important choice for how to convert the token-level embeddings into a fixed-size sentence embedding. \\nb. Dimensionality Reduction (PCA): The code also applies Principal Component Analysis (PCA) to reduce the dimensionality of the sentence embeddings to 2D \\nfor visualization purposes. This choice of dimensionality reduction technique is independent of the transformer model's architecture and is done to visualize \\nthe high-dimensional sentence embeddings. PCA is a common technique for dimensionality reduction that projects high-dimensional data into a lower-dimensional space\\nwhile preserving the most important information.\\nc. Sentence Encoding Length (max_length): In the function encode_sentences, there's a choice to limit the maximum sentence length to 128 tokens.\\nThis is a design choice for the tokenizer and could affect how longer sentences are truncated.\\nA different value for max_length could have been used based on the specific requirements of the application.\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "There are several important decisions made about the model's design beyond the main transformer part. These include:\n",
    "\n",
    "a. Pooling Strategy (Mean Pooling): After sentences pass through the transformer model, the code takes the embeddings from the last hidden state. It combines these embeddings using mean pooling, which means calculating the average of all token embeddings for a sentence. This decision is crucial for turning token-level embeddings into a fixed-size sentence embedding. By averaging, it simplifies complex sentence data into a single, manageable size without losing important information.\n",
    "\n",
    "b. Dimensionality Reduction (PCA): The code also uses Principal Component Analysis (PCA) to reduce the sentence embeddings to two dimensions, aiding visualization. This step is separate from the transformer's design and is done to help visualize complex, high-dimensional sentence embeddings in a simpler form. PCA is a widely-used method for reducing dimensions that keeps essential information, making it easier to interpret the data visually.\n",
    "\n",
    "c. Sentence Encoding Length (max_length): In the function called encode_sentences, there's a decision to limit sentence length to a maximum of 128 tokens. This choice affects how the tokenizer handles longer sentences, as it may cut off parts of the sentence beyond this limit. The max_length value can be adjusted depending on the specific needs of the application, allowing flexibility in how much sentence data is kept for processing. This choice helps in balancing between processing efficiency and retaining sentence details.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Task A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  target\n",
      "0  I rented I AM CURIOUS-YELLOW from my video sto...       0\n",
      "1  \"I Am Curious: Yellow\" is a risible and preten...       0\n",
      "2  If only to avoid making this type of film in t...       0\n",
      "3  This film was probably inspired by Godard's Ma...       0\n",
      "4  Oh, brother...after hearing about this ridicul...       0\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"imdb\")\n",
    "train_df = dataset[\"train\"].to_pandas()\n",
    "test_df = dataset[\"test\"].to_pandas()\n",
    "train_df = train_df.rename(columns={\"label\": \"target\", \"text\": \"text\"})\n",
    "test_df = test_df.rename(columns={\"label\": \"target\", \"text\": \"text\"})\n",
    "train_df[\"target\"] = train_df[\"target\"].map({0: 0, 1: 1})\n",
    "test_df[\"target\"] = test_df[\"target\"].map({0: 0, 1: 1})\n",
    "print(train_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MultiTaskSentenceTransformer(nn.Module):\n",
    "    def __init__(self, base_model, num_classes=2):\n",
    "        super(MultiTaskSentenceTransformer, self).__init__()\n",
    "        self.encoder = base_model  # DistilBERT\n",
    "        self.classifier = nn.Linear(base_model.config.hidden_size, num_classes)  \n",
    "\n",
    "    def forward(self, input_ids, attention_mask, task=\"embedding\"):\n",
    "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        sentence_embedding = outputs.last_hidden_state.mean(dim=1)  #\n",
    "\n",
    "        if task == \"classification\":\n",
    "            logits = self.classifier(sentence_embedding)  \n",
    "            return logits\n",
    "        elif task == \"embedding\":\n",
    "            return sentence_embedding  \n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "base_model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "model = MultiTaskSentenceTransformer(base_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class IMDBDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=256):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        encoding = self.tokenizer(self.texts[idx], padding=\"max_length\", truncation=True, \n",
    "                                  max_length=self.max_length, return_tensors=\"pt\")\n",
    "        input_ids = encoding[\"input_ids\"].squeeze(0)\n",
    "        attention_mask = encoding[\"attention_mask\"].squeeze(0)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "        return input_ids, attention_mask, label\n",
    " \n",
    "train_dataset = IMDBDataset(train_df[\"text\"].tolist(), train_df[\"target\"].tolist(), tokenizer)\n",
    "test_dataset = IMDBDataset(test_df[\"text\"].tolist(), test_df[\"target\"].tolist(), tokenizer)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiTaskSentenceTransformer(\n",
       "  (encoder): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gpentela\\AppData\\Local\\Temp\\ipykernel_2284\\926441083.py:9: FutureWarning:\n",
      "\n",
      "`torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "\n",
      "C:\\Users\\Gpentela\\AppData\\Local\\Temp\\ipykernel_2284\\926441083.py:31: FutureWarning:\n",
      "\n",
      "`torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=122.1516, Accuracy=0.8638\n",
      "Epoch 2: Loss=83.5314, Accuracy=0.9150\n",
      "Epoch 3: Loss=63.6314, Accuracy=0.9400\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "model.to(device)\n",
    "scaler = GradScaler()\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True, pin_memory=True)\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 3\n",
    "gradient_accumulation_steps = 2  \n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "\n",
    "    for step, (input_ids, attention_mask, labels) in enumerate(train_dataloader):\n",
    "        input_ids, attention_mask, labels = input_ids.to(device, non_blocking=True), \\\n",
    "                                            attention_mask.to(device, non_blocking=True), \\\n",
    "                                            labels.to(device, non_blocking=True)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():  \n",
    "            logits = model(input_ids, attention_mask, task=\"classification\")\n",
    "            loss = criterion(logits, labels) / gradient_accumulation_steps  \n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (step + 1) % gradient_accumulation_steps == 0 or (step + 1) == len(train_dataloader):\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        with torch.no_grad():\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f\"Epoch {epoch+1}: Loss={total_loss:.4f}, Accuracy={accuracy:.4f}\")\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9065\n",
      "Precision: 0.9074\n",
      "Recall: 0.9065\n",
      "F1-Score: 0.9065\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_ids, attention_mask, labels in dataloader:\n",
    "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "\n",
    "            logits = model(input_ids, attention_mask, task=\"classification\")\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "\n",
    "            all_targets.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(preds.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_targets, all_predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_targets, all_predictions, average=\"weighted\")\n",
    "\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "accuracy, precision, recall, f1 = evaluate_model(model, test_dataloader)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: 'This movie was absolutely fantastic! I loved every second of it.'  Sentiment: Positive\n",
      "Sentence: 'I hate this film. It was the worst experience ever!'  Sentiment: Negative\n",
      "Sentence: 'The acting was decent, but the storyline was just average.'  Sentiment: Negative\n",
      "Sentence: 'The meeting was not attended by the manager.'  Sentiment: Negative\n",
      "Sentence: 'The movie is not exceptional, but can be seen a few times '  Sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "def predict_sentiment(model, sentences):\n",
    "    model.eval()\n",
    "    inputs = tokenizer(sentences, padding=True, truncation=True, max_length=256, return_tensors=\"pt\")\n",
    "    input_ids, attention_mask = inputs[\"input_ids\"].to(device), inputs[\"attention_mask\"].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids, attention_mask, task=\"classification\")\n",
    "        predictions = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "    \n",
    "    sentiment_labels = {0: \"Negative\", 1: \"Positive\"}\n",
    "    for sentence, pred in zip(sentences, predictions):\n",
    "        print(f\"Sentence: '{sentence}'  Sentiment: {sentiment_labels[pred]}\")\n",
    "\n",
    "\n",
    "test_sentences = [\n",
    "    \"This movie was absolutely fantastic! I loved every second of it.\",\n",
    "    \"I hate this film. It was the worst experience ever!\",\n",
    "    \"The acting was decent, but the storyline was just average.\",\n",
    "    \"The meeting was not attended by the manager.\",\n",
    "    \"The movie is not exceptional, but can be seen a few times \"\n",
    "]\n",
    "\n",
    "predict_sentiment(model, test_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named Entity Recognition results:\n",
      "Entity: Hawk, Label: I-PER, Confidence: 0.9982\n",
      "Entity: ##ing, Label: I-PER, Confidence: 0.9963\n",
      "Entity: University, Label: I-ORG, Confidence: 0.9775\n",
      "Entity: of, Label: I-ORG, Confidence: 0.9815\n",
      "Entity: Cambridge, Label: I-ORG, Confidence: 0.9907\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForTokenClassification\n",
    "from transformers import pipeline\n",
    "model_name = \"dbmdz/bert-large-cased-finetuned-conll03-english\"  \n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForTokenClassification.from_pretrained(model_name)\n",
    "nlp_ner = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "text = \"Hawking was a theoretical physicist at the University of Cambridge.\"\n",
    "\n",
    "ner_results = nlp_ner(text)\n",
    "\n",
    "print(\"Named Entity Recognition results:\")\n",
    "for entity in ner_results:\n",
    "    print(f\"Entity: {entity['word']}, Label: {entity['entity']}, Confidence: {entity['score']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Named Entity Recognition results:\n",
      "Entity: Hawk, Label: I-PER, Confidence: 0.9977\n",
      "Entity: ##ing, Label: I-PER, Confidence: 0.9946\n",
      "Entity: University, Label: I-ORG, Confidence: 0.9566\n",
      "Entity: of, Label: I-ORG, Confidence: 0.9778\n",
      "Entity: Cambridge, Label: I-ORG, Confidence: 0.9764\n",
      "Entity: AI, Label: I-MISC, Confidence: 0.9890\n",
      "\n",
      "Sentiment Analysis results:\n",
      "Label: POSITIVE, Confidence: 0.9988\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForTokenClassification, DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "model_name_ner = \"dbmdz/bert-large-cased-finetuned-conll03-english\"  \n",
    "tokenizer = BertTokenizer.from_pretrained(model_name_ner)\n",
    "model_ner = BertForTokenClassification.from_pretrained(model_name_ner)\n",
    "\n",
    "nlp_ner = pipeline(\"ner\", model=model_ner, tokenizer=tokenizer)\n",
    "\n",
    "model_name_sentiment = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "sentiment_model = DistilBertForSequenceClassification.from_pretrained(model_name_sentiment)\n",
    "\n",
    "sentiment_tokenizer = DistilBertTokenizer.from_pretrained(model_name_sentiment)\n",
    "\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\", model=sentiment_model, tokenizer=sentiment_tokenizer)\n",
    "\n",
    "text = \"Hawking was a theoretical physicist at the University of Cambridge. I love studying AI!\"\n",
    "\n",
    "ner_results = nlp_ner(text)\n",
    "\n",
    "sentiment_results = sentiment_pipeline(text)\n",
    "\n",
    "print(\"Named Entity Recognition results:\")\n",
    "for entity in ner_results:\n",
    "    print(f\"Entity: {entity['word']}, Label: {entity['entity']}, Confidence: {entity['score']:.4f}\")\n",
    "\n",
    "print(\"\\nSentiment Analysis results:\")\n",
    "for sentiment in sentiment_results:\n",
    "    print(f\"Label: {sentiment['label']}, Confidence: {sentiment['score']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nChanges Made to Architecture to support multi-task learning\\n\\nModel Architecture: Designed a model called MultiTaskSentenceTransformer. This model can do two things: create sentence embeddings or provide classification results, depending on what is needed.\\n\\nDataset Class: Created a special class to prepare the IMDB dataset. This class helps break down sentences into smaller parts called tokens and makes input-output pairs for both sentence embedding and classification tasks.\\n\\nTraining and Evaluation: Made the training process more efficient by using mixed-precision, which speeds it up. Also added a function to check how well the model is doing by measuring its performance. This model design lets the model handle multiple tasks at once, such as creating sentence embeddings and classifying data, using just one model.\\n\\nTraining Pipeline: Enhanced the training loop to deal with different tasks and their specific loss calculations.\\n\\nEvaluation Pipeline: Introduced functions to the evaluation process that calculate important performance metrics based on the task being performed.\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Changes Made to Architecture to support multi-task learning\n",
    "\n",
    "Model Architecture: Designed a model called MultiTaskSentenceTransformer. This model can do two things: create sentence embeddings or provide classification results, depending on what is needed.\n",
    "Dataset Class: Created a special class to prepare the IMDB dataset. This class helps break down sentences into smaller parts called tokens and makes input-output pairs for both sentence embedding and classification tasks.\n",
    "Training and Evaluation: Made the training process more efficient by using mixed-precision, which speeds it up. Also added a function to check how well the model is doing by measuring its performance. This model design lets the model handle multiple tasks at once, such as creating sentence embeddings and classifying data, using just one model.\n",
    "Training Pipeline: Enhanced the training loop to deal with different tasks and their specific loss calculations.\n",
    "Evaluation Pipeline: Introduced functions to the evaluation process that calculate important performance metrics based on the task being performed.\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
